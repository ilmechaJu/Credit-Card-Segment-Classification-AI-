# -*- coding: utf-8 -*-
"""CreditCard-baseline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xy9H3JZt_vifw5C6BUdcNoalvXapEHfW

### Import
"""

import pandas as pd
import numpy as np
import gc
import os
import warnings
warnings.filterwarnings('ignore')

import xgboost as xgb
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from tqdm import tqdm

"""### Data Load"""

# 데이터 분할(폴더) 구분
data_splits = ["train", "test"]

# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정
data_categories = {
    "회원정보": {"folder": "1.회원정보", "suffix": "회원정보", "var_prefix": "customer"},
    "신용정보": {"folder": "2.신용정보", "suffix": "신용정보", "var_prefix": "credit"},
    "승인매출정보": {"folder": "3.승인매출정보", "suffix": "승인매출정보", "var_prefix": "sales"},
    "청구정보": {"folder": "4.청구입금정보", "suffix": "청구정보", "var_prefix": "billing"},
    "잔액정보": {"folder": "5.잔액정보", "suffix": "잔액정보", "var_prefix": "balance"},
    "채널정보": {"folder": "6.채널정보", "suffix": "채널정보", "var_prefix": "channel"},
    "마케팅정보": {"folder": "7.마케팅정보", "suffix": "마케팅정보", "var_prefix": "marketing"},
    "성과정보": {"folder": "8.성과정보", "suffix": "성과정보", "var_prefix": "performance"}
}

# 2018년 7월부터 12월까지의 월 리스트
months = ['07', '08', '09', '10', '11', '12']

def load_data():
    data_dict = {}
    for split in data_splits:
        for category, info in data_categories.items():
            folder = info["folder"]
            suffix = info["suffix"]
            var_prefix = info["var_prefix"]
            
            for month in months:
                try:
                    file_path = os.path.join(split, folder, f"2018{month}_{split}_{suffix}.parquet")
                    if not os.path.exists(file_path):
                        print(f"Warning: File not found: {file_path}")
                        continue
                        
                    variable_name = f"{var_prefix}_{split}_{month}"
                    data_dict[variable_name] = pd.read_parquet(file_path)
                    print(f"{variable_name} is loaded from {file_path}")
                except Exception as e:
                    print(f"Error loading {file_path}: {str(e)}")
                    
    return data_dict

# 데이터 로드
print("데이터 로딩 시작...")
data_dict = load_data()
gc.collect()

def merge_dataframes(df_dict, split):
    """데이터프레임 병합 함수"""
    result_df = None
    merge_order = ["customer", "credit", "sales", "billing", "balance", "channel", "marketing", "performance"]
    
    for prefix in merge_order:
        df_list = [df_dict[f"{prefix}_{split}_{month}"] for month in months if f"{prefix}_{split}_{month}" in df_dict]
        if not df_list:
            continue
            
        current_df = pd.concat(df_list, axis=0)
        if result_df is None:
            result_df = current_df
        else:
            result_df = result_df.merge(current_df, on=['기준년월', 'ID'], how='left')
            del current_df
            gc.collect()
            
    return result_df

# Train 데이터 병합
print("\nTrain 데이터 병합 시작...")
train_df = merge_dataframes(data_dict, "train")
print("Train data merged, shape:", train_df.shape)

# Test 데이터 병합
print("\nTest 데이터 병합 시작...")
test_df = merge_dataframes(data_dict, "test")
print("Test data merged, shape:", test_df.shape)

# 메모리 정리
del data_dict
gc.collect()

# 타겟 변수 처리
if "Segment" not in train_df.columns:
    print("Error: Target variable 'Segment' not found in training data")
    exit(1)

feature_cols = [col for col in train_df.columns if col not in ["ID", "Segment", "기준년월"]]

# 데이터 타입 최적화
print("\n데이터 타입 최적화 시작...")
for col in tqdm(feature_cols, desc="데이터 타입 변환"):
    if train_df[col].dtype == 'object':
        train_df[col] = train_df[col].astype('category')
        test_df[col] = test_df[col].astype('category')
    elif train_df[col].dtype == 'float64':
        train_df[col] = train_df[col].astype('float32')
        test_df[col] = test_df[col].astype('float32')
    elif train_df[col].dtype == 'int64':
        train_df[col] = train_df[col].astype('int32')
        test_df[col] = test_df[col].astype('int32')

X = train_df[feature_cols].copy()
y = train_df["Segment"].copy()

# 학습/검증 데이터 분할
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# 타깃 라벨 인코딩
print("\n타겟 변수 인코딩 시작...")
le_target = LabelEncoder()
y_train_encoded = le_target.fit_transform(y_train)
y_val_encoded = le_target.transform(y_val)

# 범주형 변수 처리
print("\n범주형 변수 인코딩 시작...")
categorical_features = X_train.select_dtypes(include=['category']).columns.tolist()
X_test = test_df[feature_cols].copy()

encoders = {}
for col in tqdm(categorical_features, desc="범주형 변수 인코딩"):
    try:
        le_train = LabelEncoder()
        X_train[col] = le_train.fit_transform(X_train[col].astype(str))
        X_val[col] = le_train.transform(X_val[col].astype(str))
        encoders[col] = le_train
        X_test[col] = le_train.transform(X_test[col].astype(str))
    except Exception as e:
        print(f"Error encoding column {col}: {str(e)}")
        continue

gc.collect()

"""### Train"""

# XGBoost 모델 파라미터
params = {
    'random_state': 42,
    'n_jobs': -1,
    'tree_method': 'hist',
    'max_depth': 6,
    'learning_rate': 0.1,
    'n_estimators': 100,
    'enable_categorical': True,
    'eval_metric': ['mlogloss', 'merror'],
    'objective': 'multi:softmax',
    'num_class': len(np.unique(y_train_encoded))
}

# DMatrix 생성
dtrain = xgb.DMatrix(X_train, label=y_train_encoded)
dval = xgb.DMatrix(X_val, label=y_val_encoded)

# 학습
print("\n모델 학습 시작...")
model = xgb.train(
    params,
    dtrain,
    num_boost_round=100,
    evals=[(dtrain, 'train'), (dval, 'val')],
    verbose_eval=10
)

# 검증 데이터 예측
print("\n검증 데이터 예측 및 평가...")
y_val_pred = model.predict(dval)
y_val_pred_labels = le_target.inverse_transform(y_val_pred.astype(int))
y_val_true_labels = le_target.inverse_transform(y_val_encoded)

# 성능 평가
print("\n=== 검증 데이터 성능 평가 ===")
print("\nConfusion Matrix:")
print(confusion_matrix(y_val_true_labels, y_val_pred_labels))
print("\nClassification Report:")
print(classification_report(y_val_true_labels, y_val_pred_labels))

"""### Predict"""

print("\n테스트 데이터 예측 시작...")
dtest = xgb.DMatrix(X_test)
y_test_pred = model.predict(dtest)
y_test_pred_labels = le_target.inverse_transform(y_test_pred.astype(int))

# 제출 파일 생성
print("\n제출 파일 생성 중...")
submission = pd.DataFrame({
    "ID": test_df["ID"],
    "Segment": y_test_pred_labels
})

submission = submission.groupby("ID")["Segment"].agg(lambda x: x.value_counts().idxmax()).reset_index()
submission.to_csv('submission.csv', index=False)
print("제출 파일이 생성되었습니다.")